{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import glob\n",
    "from collections import defaultdict \n",
    "from collections import OrderedDict as od\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warriner = {}\n",
    "with open(filepath+'warriner.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    next(reader)\n",
    "    warriner = {rows[1]: {'valence': (float)(rows[2]), 'arousal': (float)(rows[5]), 'dominance': (float)(rows[8])} for rows in reader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Approach\n",
    "\n",
    "Just taking the previous code and generalizing it a bit more to put in arbitrary works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_breakdown(n, prop, min_thresh, filename):\n",
    "    f = filepath+filename\n",
    "    ngrams = defaultdict(list)\n",
    "    text = defaultdict(float)\n",
    "\n",
    "    # Load it in and collect frequency for each word\n",
    "    with open(f, mode='r') as infile:\n",
    "        for line in infile:\n",
    "            line = re.sub('[.,?!#$\\'\\\"\\(\\)\\d_;]', '', line)\n",
    "            for word in line.split():\n",
    "                word = word.lower()\n",
    "                if word in warriner:\n",
    "                    text[word] += 1\n",
    "\n",
    "    # Load it in again. If the word is viable, collect an N-Gram and store it\n",
    "\n",
    "    with open(f, mode='r') as infile:\n",
    "        prev_line = \"\"\n",
    "        word_cap = []\n",
    "        for line in infile:\n",
    "            line = re.sub('[.,?!#$\\'\\\"\\(\\)\\d_;]', '', line)\n",
    "            line_split = line.split()\n",
    "\n",
    "            while len(word_cap) > 0:\n",
    "                word = word_cap.pop(0)\n",
    "                ind = word_cap.pop(0)\n",
    "                if ind < len(line_split):\n",
    "                    if line_split[ind] in warriner and line_split[ind] != word:\n",
    "                        ngrams[word].append(line_split[ind])\n",
    "            for i, word in enumerate(line_split):\n",
    "                word = word.lower()\n",
    "                if word in text:\n",
    "                    if warriner[word][prop] > min_thresh: \n",
    "                        for j in range(1, n+1):\n",
    "                            if i-j >= 0:\n",
    "                                if line_split[i-j] in warriner and line_split[i-j] != word:\n",
    "                                    ngrams[word].append(line_split[i-j])\n",
    "                            else:\n",
    "                                if abs(i-j) < len(prev_line):\n",
    "                                    if prev_line != \"\" and prev_line[i-j] in warriner and prev_line[i-j] != word:\n",
    "                                        ngrams[word].append(prev_line[i-j])\n",
    "\n",
    "                            if i+j < len(line_split):\n",
    "                                if line_split[i+j] in warriner:\n",
    "                                    ngrams[word].append(line_split[i+j])\n",
    "                            else:\n",
    "                                word_cap.append(word)\n",
    "                                word_cap.append(j-1)\n",
    "            prev_line = line_split\n",
    "\n",
    "    text['_valence'] = 0\n",
    "    text['_dominance'] = 0\n",
    "    text['_arousal'] = 0\n",
    "    count = 0\n",
    "    for word in text:\n",
    "        if word in warriner:\n",
    "            count += text[word]\n",
    "            text['_valence'] += warriner[word]['valence'] * text[word]\n",
    "            text['_dominance'] += warriner[word]['dominance'] * text[word]\n",
    "            text['_arousal'] += warriner[word]['arousal'] * text[word]\n",
    "    text['_valence'] /= count\n",
    "    text['_dominance'] /= count\n",
    "    text['_arousal'] /= count\n",
    "\n",
    "    ngram_table = {}\n",
    "    for word in ngrams:\n",
    "        ngram_table[word] = Counter(ngrams[word])\n",
    "        \n",
    "    return (text, ngram_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_breakdown(2, 'arousal', 3, 'dracula.txt')[0]['blood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transfusion', 4),\n",
       " ('fresh', 4),\n",
       " ('bloom', 3),\n",
       " ('cold', 3),\n",
       " ('drop', 3),\n",
       " ('give', 2),\n",
       " ('four', 2),\n",
       " ('life', 2),\n",
       " ('run', 2),\n",
       " ('suck', 2),\n",
       " ('pool', 2),\n",
       " ('must', 2),\n",
       " ('loss', 2),\n",
       " ('baptism', 2),\n",
       " ('lost', 2),\n",
       " ('lose', 2),\n",
       " ('draw', 1),\n",
       " ('brave', 1),\n",
       " ('have', 1),\n",
       " ('stream', 1),\n",
       " ('dance', 1),\n",
       " ('side', 1),\n",
       " ('back', 1),\n",
       " ('lust', 1),\n",
       " ('want', 1),\n",
       " ('remembrance', 1),\n",
       " ('pain', 1),\n",
       " ('eyes', 1),\n",
       " ('children', 1),\n",
       " ('lead', 1),\n",
       " ('trance', 1),\n",
       " ('kin', 1),\n",
       " ('flesh', 1),\n",
       " ('poison', 1),\n",
       " ('take', 1),\n",
       " ('pure', 1),\n",
       " ('waste', 1),\n",
       " ('smell', 1),\n",
       " ('red', 1),\n",
       " ('time', 1),\n",
       " ('lay', 1),\n",
       " ('clot', 1),\n",
       " ('come', 1),\n",
       " ('dog', 1),\n",
       " ('remove', 1),\n",
       " ('keep', 1),\n",
       " ('mean', 1),\n",
       " ('make', 1),\n",
       " ('blood', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_breakdown(2, 'arousal', 3, 'dracula.txt')[1]['blood'].most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lust', 6.44),\n",
       " ('pain', 6.27),\n",
       " ('poison', 6.01),\n",
       " ('blood', 5.76),\n",
       " ('suck', 5.6),\n",
       " ('life', 5.59),\n",
       " ('dance', 5.48),\n",
       " ('dog', 5.43),\n",
       " ('lose', 5.43),\n",
       " ('want', 5.29),\n",
       " ('smell', 5.24),\n",
       " ('run', 5.24),\n",
       " ('loss', 5.2),\n",
       " ('lost', 5.11),\n",
       " ('children', 5.09),\n",
       " ('red', 5.02),\n",
       " ('brave', 4.95),\n",
       " ('bloom', 4.87),\n",
       " ('mean', 4.81),\n",
       " ('drop', 4.67),\n",
       " ('give', 4.57),\n",
       " ('take', 4.52),\n",
       " ('transfusion', 4.45),\n",
       " ('stream', 4.35),\n",
       " ('remembrance', 4.35),\n",
       " ('clot', 4.17),\n",
       " ('flesh', 4.11),\n",
       " ('must', 4.1),\n",
       " ('pure', 4.05),\n",
       " ('waste', 4.04),\n",
       " ('trance', 4.0),\n",
       " ('baptism', 3.96),\n",
       " ('lead', 3.95),\n",
       " ('lay', 3.7),\n",
       " ('make', 3.67),\n",
       " ('pool', 3.65),\n",
       " ('draw', 3.6),\n",
       " ('come', 3.57),\n",
       " ('cold', 3.55),\n",
       " ('have', 3.52),\n",
       " ('keep', 3.43),\n",
       " ('time', 3.41),\n",
       " ('four', 3.39),\n",
       " ('eyes', 3.18),\n",
       " ('side', 3.14),\n",
       " ('remove', 3.11),\n",
       " ('kin', 3.0),\n",
       " ('back', 2.59),\n",
       " ('fresh', 2.35)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(w, warriner[w]['arousal']) for w in get_breakdown(2, 'arousal', 3, 'dracula.txt')[1]['blood']], key=lambda d: d[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Interface, Examples\n",
    "\n",
    "Below is a very simplified interface for playing with these various things and playing with the learned concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_list(breakdown, prop):\n",
    "    return sorted([(warriner[w][prop], w, breakdown[0][w]) for w in breakdown[0] if w in warriner], reverse=True)\n",
    "def related(breakdown, prop, keyword):\n",
    "    if keyword in breakdown[1]:\n",
    "        return sorted([(w, warriner[w][prop]) for w in breakdown[1][keyword]], key=lambda d: d[1], reverse=True)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles = ['holmes', 'alice', 'dracula', 'pride', 'raven']\n",
    "texts = {}\n",
    "for title in titles:\n",
    "    texts[title] = get_breakdown(2, 'arousal', 3, title + \".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword:  sad\n",
      "holmes \n",
      "[('tragedy', 6.8), ('anxious', 6.2), ('news', 4.61), ('look', 3.76)] \n",
      "\n",
      "dracula \n",
      "[('accident', 4.93), ('broken', 4.86), ('news', 4.61), ('world', 4.55), ('blow', 4.48), ('terrible', 4.39), ('little', 4.2), ('case', 4.14), ('feel', 4.05), ('distress', 4.0), ('toll', 3.95), ('truth', 3.88), ('experience', 3.71), ('be', 3.43), ('hour', 3.38), ('humble', 3.18), ('will', 2.9), ('slow', 2.89), ('accept', 2.8)] \n",
      "\n",
      "pride \n",
      "[('affair', 5.4), ('omen', 4.52), ('business', 3.71), ('cousin', 2.6)] \n",
      "\n",
      "alice \n",
      "[('lonely', 4.37), ('distance', 3.81)] \n",
      "\n",
      "raven \n",
      "[('fancy', 5.42), ('uncertain', 4.45), ('silken', 2.7)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "search = 'sad'\n",
    "print 'Keyword: ', search\n",
    "\n",
    "for text in texts:\n",
    "    print text, '\\n', related(texts[text], 'arousal', search), '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword:  anger\n",
      "holmes \n",
      "[('surprise', 6.57), ('fear', 6.14), ('burst', 5.09), ('fit', 4.35), ('would', 3.81)] \n",
      "\n",
      "dracula \n",
      "[('arouse', 6.21), ('sheer', 5.55), ('hellish', 4.48), ('stamp', 3.45)] \n",
      "\n",
      "pride \n",
      "[('compassion', 4.5), ('treatment', 4.47), ('think', 3.75), ('be', 3.43), ('pale', 3.18)] \n",
      "\n",
      "alice \n",
      "[] \n",
      "\n",
      "raven \n",
      "[] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "search = 'anger'\n",
    "print 'Keyword: ', search\n",
    "\n",
    "for text in texts:\n",
    "    print text, '\\n', related(texts[text], 'arousal', search), '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword:  time\n",
      "holmes \n",
      "[('right', 7.16), ('thank', 6.89), ('breakfast', 6.83), ('hope', 6.78), ('will', 6.61), ('order', 6.56), ('free', 6.5), ('think', 6.5), ('manual', 6.48), ('first', 6.38), ('do', 6.35), ('silence', 6.26), ('whole', 6.24), ('prevent', 6.21), ('thought', 6.15), ('matter', 6.12), ('valuable', 6.04), ('observation', 6.04), ('see', 6.0), ('possible', 6.0), ('influence', 5.96), ('commence', 5.95), ('lip', 5.95), ('close', 5.94), ('would', 5.94), ('put', 5.94), ('come', 5.94), ('life', 5.89), ('set', 5.81), ('rectify', 5.81), ('have', 5.72), ('colonel', 5.72), ('keep', 5.71), ('spare', 5.63), ('day', 5.59), ('one', 5.56), ('feel', 5.5), ('be', 5.5), ('raise', 5.44), ('little', 5.18), ('stop', 5.06), ('tell', 4.94), ('take', 4.83), ('saw', 4.67), ('station', 4.61), ('waste', 4.58), ('break', 4.5), ('end', 4.41), ('short', 4.39), ('time', 4.36), ('evil', 3.6), ('decrepit', 3.46), ('police', 3.44), ('dreadful', 3.38), ('war', 3.27)] \n",
      "\n",
      "dracula \n",
      "[('incredible', 7.74), ('strength', 7.42), ('skill', 7.41), ('comfort', 7.18), ('complete', 7.17), ('right', 7.16), ('correct', 7.06), ('experience', 6.94), ('arrive', 6.84), ('choose', 6.83), ('breakfast', 6.83), ('sure', 6.82), ('useful', 6.81), ('reply', 6.79), ('certain', 6.78), ('regular', 6.74), ('bed', 6.73), ('hear', 6.71), ('pretty', 6.7), ('logic', 6.7), ('present', 6.65), ('will', 6.61), ('usual', 6.58), ('believe', 6.56), ('condition', 6.53), ('place', 6.53), ('considerable', 6.52), ('think', 6.5), ('nice', 6.47), ('can', 6.44), ('resolution', 6.42), ('good', 6.41), ('first', 6.38), ('save', 6.34), ('friend', 6.31), ('ask', 6.29), ('voice', 6.22), ('make', 6.22), ('become', 6.18), ('action', 6.17), ('times', 6.12), ('read', 6.11), ('act', 6.11), ('case', 6.11), ('pace', 6.11), ('process', 6.11), ('succeed', 6.1), ('mind', 6.09), ('let', 6.06), ('observation', 6.04), ('possible', 6.0), ('carriage', 6.0), ('other', 6.0), ('sunrise', 5.95), ('send', 5.94), ('come', 5.94), ('would', 5.94), ('eyes', 5.94), ('close', 5.94), ('may', 5.94), ('woman', 5.93), ('life', 5.89), ('shall', 5.89), ('light', 5.89), ('reasonable', 5.88), ('question', 5.88), ('ship', 5.84), ('rest', 5.78), ('know', 5.78), ('precious', 5.75), ('shop', 5.72), ('give', 5.72), ('have', 5.72), ('wake', 5.71), ('exact', 5.7), ('get', 5.65), ('replace', 5.61), ('call', 5.61), ('one', 5.56), ('be', 5.5), ('start', 5.5), ('black', 5.48), ('leave', 5.47), ('catch', 5.47), ('suck', 5.47), ('run', 5.44), ('penetrate', 5.41), ('brief', 5.39), ('second', 5.35), ('go', 5.33), ('sunset', 5.32), ('sleep', 5.3), ('strange', 5.28), ('write', 5.28), ('chance', 5.25), ('past', 5.18), ('little', 5.18), ('move', 5.12), ('visit', 5.06), ('must', 5.06), ('two', 5.05), ('sun', 4.98), ('deep', 4.94), ('way', 4.83), ('take', 4.83), ('round', 4.78), ('pass', 4.78), ('remaining', 4.76), ('saw', 4.67), ('dark', 4.61), ('unusual', 4.55), ('masses', 4.54), ('end', 4.41), ('lose', 4.39), ('short', 4.39), ('time', 4.36), ('dreary', 4.28), ('distance', 4.25), ('old', 4.22), ('scared', 4.2), ('blood', 3.94), ('mortal', 3.88), ('miserable', 3.86), ('lost', 3.85), ('weakness', 3.81), ('due', 3.72), ('loneliness', 3.61), ('bear', 3.59), ('forget', 3.5), ('horror', 3.49), ('pain', 3.47), ('death', 3.42), ('terrible', 3.4), ('dreadful', 3.38), ('fear', 3.32), ('endless', 3.25), ('enemy', 2.5)] \n",
      "\n",
      "pride \n",
      "[('courage', 7.27), ('consideration', 7.11), ('correct', 7.06), ('gracious', 7.05), ('perseverance', 6.89), ('breakfast', 6.83), ('reply', 6.79), ('speech', 6.68), ('great', 6.65), ('express', 6.57), ('considerable', 6.52), ('music', 6.5), ('think', 6.5), ('can', 6.44), ('good', 6.41), ('first', 6.38), ('pay', 6.33), ('remember', 6.31), ('conversation', 6.28), ('make', 6.22), ('beautiful', 6.17), ('thought', 6.15), ('likely', 6.14), ('regain', 6.08), ('consider', 6.06), ('grove', 6.05), ('dinner', 6.05), ('see', 6.0), ('other', 6.0), ('intercourse', 6.0), ('answer', 5.95), ('would', 5.94), ('accept', 5.94), ('may', 5.94), ('come', 5.94), ('speak', 5.89), ('life', 5.89), ('shall', 5.89), ('year', 5.81), ('precious', 5.75), ('give', 5.72), ('have', 5.72), ('ceremony', 5.67), ('spare', 5.63), ('third', 5.61), ('one', 5.56), ('confess', 5.53), ('future', 5.53), ('be', 5.5), ('leave', 5.47), ('want', 5.39), ('second', 5.35), ('go', 5.33), ('write', 5.28), ('supply', 5.24), ('supposed', 5.24), ('little', 5.18), ('haughty', 5.09), ('two', 5.05), ('space', 4.98), ('tell', 4.94), ('ten', 4.8), ('remove', 4.56), ('alone', 4.5), ('loss', 4.47), ('ostentatious', 4.4), ('short', 4.39), ('vague', 4.19), ('mean', 4.17), ('difficult', 3.78), ('due', 3.72), ('dreaded', 3.5)] \n",
      "\n",
      "alice \n",
      "[('hear', 6.71), ('great', 6.65), ('alarm', 6.58), ('wash', 6.53), ('morning', 6.35), ('hint', 6.05), ('see', 6.0), ('life', 5.89), ('high', 5.76), ('have', 5.72), ('air', 5.72), ('begin', 5.72), ('beat', 5.59), ('day', 5.59), ('one', 5.56), ('be', 5.5), ('label', 5.48), ('second', 5.35), ('go', 5.33), ('avoid', 4.81), ('round', 4.78), ('saw', 4.67), ('short', 4.39)] \n",
      "\n",
      "raven \n",
      "[] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "search = 'time'\n",
    "print 'Keyword: ', search\n",
    "\n",
    "for text in texts:\n",
    "    print text, '\\n', related(texts[text], 'dominance', search), '\\n' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valence\n",
      "----------\n",
      "\n",
      "holmes :  5.67676919194\n",
      "dracula :  5.67917595918\n",
      "pride :  5.88645457006\n",
      "alice :  5.76507903056\n",
      "raven :  5.36217712177\n",
      "\n",
      " Dominance\n",
      "----------\n",
      "\n",
      "holmes :  5.5983186096\n",
      "dracula :  5.55997188622\n",
      "pride :  5.72432852987\n",
      "alice :  5.6260424507\n",
      "raven :  5.42151291513\n",
      "\n",
      " Arousal\n",
      "----------\n",
      "\n",
      "holmes :  3.93258284354\n",
      "dracula :  3.9690989416\n",
      "pride :  3.99732765036\n",
      "alice :  3.91886045461\n",
      "raven :  4.02664206642\n"
     ]
    }
   ],
   "source": [
    "print '\\n Valence\\n----------\\n'\n",
    "\n",
    "for text in texts:\n",
    "   print text, ': ', texts[text][0]['_valence']\n",
    "\n",
    "print '\\n Dominance\\n----------\\n'\n",
    "\n",
    "for text in texts:\n",
    "   print text, ': ', texts[text][0]['_dominance']\n",
    "\n",
    "print '\\n Arousal\\n----------\\n'\n",
    "\n",
    "for text in texts:\n",
    "   print text, ': ', texts[text][0]['_arousal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
